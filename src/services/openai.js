const OpenAI = require('openai');

class OpenAIService {
    constructor() {
        if (!process.env.OPENAI_API_KEY) {
            console.warn('âš ï¸ OPENAI_API_KEY nicht gefunden. KI-Features funktionieren nicht.');
            this.client = null;
            return;
        }

        this.client = new OpenAI({
            apiKey: process.env.OPENAI_API_KEY,
        });

        console.log('âœ… OpenAI Service initialisiert');
    }

    async quickChat(message, userContext = {}) {
        if (!this.client) {
            throw new Error('OpenAI API nicht konfiguriert');
        }

        try {
            const systemPrompt = `Du bist ALL-KI, ein smarter und hilfsbereiter Alltagsassistent. 
Du hilfst Benutzern bei verschiedenen Aufgaben und beantwortest Fragen freundlich und prÃ¤zise.
Antworte auf Deutsch und halte deine Antworten informativ aber nicht zu lang.
${userContext.name ? `Der Benutzer heiÃŸt ${userContext.name}.` : ''}`;

            const completion = await this.client.chat.completions.create({
                model: "gpt-3.5-turbo",
                messages: [
                    {
                        role: "system",
                        content: systemPrompt
                    },
                    {
                        role: "user",
                        content: message
                    }
                ],
                max_tokens: 500,
                temperature: 0.7,
            });

            return completion.choices[0].message.content.trim();
        } catch (error) {
            console.error('OpenAI Quick Chat Error:', error);
            throw new Error('KI-Antwort konnte nicht generiert werden');
        }
    }

    async profileInterview(message, conversationHistory = [], profileData = {}) {
        if (!this.client) {
            throw new Error('OpenAI API nicht konfiguriert');
        }

        try {
            // âœ… DYNAMISCHES INTERVIEW basierend auf User-Input
            const systemPrompt = `Du bist ein intelligenter Profil-Interview-Assistent von ALL-KI.

ZIEL: Sammle Informationen fÃ¼r ein personalisiertes KI-Profil basierend auf dem User-Input.

VERHALTEN:
1. ERSTE ANTWORT: BestÃ¤tige den Profilnamen (EXAKT wie User eingegeben, nur Rechtschreibung korrigieren) und stelle eine spezifische Frage
2. FOLGENDE FRAGEN: Baue intelligent auf vorherigen Antworten auf
3. ERKENNE AUTOMATISCH: Ziele, Vorlieben, Herausforderungen, Erfahrungslevel, HÃ¤ufigkeit
4. ADAPTIERE FRAGEN: Je nach Thema - sei spezifisch!

BEISPIEL-FLOWS:
User: "Sport" 
â†’ "Perfekt! Ich erstelle ein 'Sport' Profil fÃ¼r dich. Welche Sportart machst du am liebsten?"

User: "Kochen lernen"
â†’ "Super! Ich erstelle ein 'Kochen Lernen' Profil. Welche Art von KÃ¼che interessiert dich am meisten?"

User: "Arbeit projekte" 
â†’ "Toll! Ich erstelle ein 'Arbeit Projekte' Profil. In welchem Bereich arbeitest du?"

WICHTIG:
- Halte Fragen kurz, spezifisch und motivierend
- Nach 4-5 relevanten Fragen sage: "Vielen Dank! Ich habe genug Informationen fÃ¼r dein personalisiertes '${this.getProfileNameFromHistory(conversationHistory)}' Profil gesammelt."
- Stelle nur EINE Frage pro Antwort
- Sei enthusiastisch und unterstÃ¼tzend

Bisherige GesprÃ¤ch: ${conversationHistory.length > 0 ? 'Hat bereits begonnen' : 'Erstes Interview'}
Profil-Context: ${Object.keys(profileData).length > 0 ? JSON.stringify(profileData) : 'Neues Profil wird erstellt'}`;

            // Build conversation history
            const messages = [
                {
                    role: "system",
                    content: systemPrompt
                }
            ];

            // Add conversation history
            conversationHistory.forEach(msg => {
                messages.push({
                    role: msg.role,
                    content: msg.content
                });
            });

            // Add current message
            messages.push({
                role: "user",
                content: message
            });

            const completion = await this.client.chat.completions.create({
                model: "gpt-3.5-turbo",
                messages: messages,
                max_tokens: 300,
                temperature: 0.8,
            });

            return completion.choices[0].message.content.trim();
        } catch (error) {
            console.error('OpenAI Profile Interview Error:', error);
            throw new Error('Interview-Antwort konnte nicht generiert werden');
        }
    }

    // âœ… Helper function to extract profile name from first user message
    getProfileNameFromHistory(conversationHistory) {
        if (conversationHistory.length > 0) {
            const firstUserMessage = conversationHistory.find(msg => msg.role === 'user');
            return firstUserMessage ? firstUserMessage.content : 'Profil';
        }
        return 'Profil';
    }

    async extractProfileData(conversationHistory) {
        if (!this.client) {
            throw new Error('OpenAI API nicht konfiguriert');
        }

        try {
            // âœ… VERBESSERTER PROMPT fÃ¼r freie Kategorien
            const systemPrompt = `Analysiere das folgende Interview und extrahiere strukturierte Profildaten.

WICHTIG fÃ¼r "name" und "category":
- Der "name" soll dem ursprÃ¼nglichen User-Input sehr Ã¤hnlich sein (nur Rechtschreibung/GroÃŸschreibung korrigieren)
- Die "category" soll eine bereinigte, kurze Version des Namens sein
- Beispiele:
  - User sagt "sport" â†’ name: "Sport", category: "Sport" 
  - User sagt "kochen lernen" â†’ name: "Kochen Lernen", category: "Kochen"
  - User sagt "arbeit projekkte" â†’ name: "Arbeit Projekte", category: "Arbeit"
  - User sagt "fitness training" â†’ name: "Fitness Training", category: "Fitness"

EXTRAHIERE aus dem GesprÃ¤ch:
- goals: Konkrete Ziele die erwÃ¤hnt wurden
- preferences: Was der User mag, bevorzugt oder gerne macht
- challenges: Schwierigkeiten oder Herausforderungen
- frequency: Wie oft sich der User damit beschÃ¤ftigt
- experience: Erfahrungslevel (AnfÃ¤nger/Fortgeschritten/Experte)
- notes: Wichtige Zusatzinfos oder Kontext

FORMAT (EXAKT so ausgeben):
{
  "name": "Exakt wie User wollte (nur saubere Rechtschreibung)",
  "category": "Kurze bereinigte Kategorie", 
  "goals": ["Konkrete Ziele aus dem GesprÃ¤ch"],
  "preferences": ["Was der User mag/bevorzugt"],
  "challenges": ["Herausforderungen die erwÃ¤hnt wurden"],
  "frequency": "Wie oft beschÃ¤ftigt sich der User damit",
  "experience": "AnfÃ¤nger/Fortgeschritten/Experte",
  "notes": "Wichtige Zusatzinfos aus dem GesprÃ¤ch"
}

Antworte NUR mit dem JSON-Objekt, keine zusÃ¤tzlichen ErklÃ¤rungen oder Markdown.`;

            const conversationText = conversationHistory
                .map(msg => `${msg.role}: ${msg.content}`)
                .join('\n');

            const completion = await this.client.chat.completions.create({
                model: "gpt-3.5-turbo",
                messages: [
                    {
                        role: "system",
                        content: systemPrompt
                    },
                    {
                        role: "user",
                        content: conversationText
                    }
                ],
                max_tokens: 400,
                temperature: 0.3,
            });

            const response = completion.choices[0].message.content.trim();
            console.log('ðŸ”¹ Raw OpenAI response:', response);
            
            // âœ… ROBUSTES JSON PARSING
            let parsedData;
            try {
                // Remove potential markdown formatting
                const cleanResponse = response.replace(/```json\n?/g, '').replace(/```\n?/g, '');
                parsedData = JSON.parse(cleanResponse);
            } catch (parseError) {
                console.error('ðŸ”¹ JSON parse error:', parseError);
                console.error('ðŸ”¹ Response was:', response);
                
                // âœ… INTELLIGENTER FALLBACK basierend auf ersten User-Input
                const firstUserMessage = conversationHistory.find(msg => msg.role === 'user');
                const userInput = firstUserMessage ? firstUserMessage.content : 'Profil';
                
                parsedData = {
                    name: this.cleanProfileName(userInput),
                    category: this.extractCategory(userInput),
                    goals: this.extractGoalsFromConversation(conversationHistory),
                    preferences: this.extractPreferencesFromConversation(conversationHistory),
                    challenges: this.extractChallengesFromConversation(conversationHistory),
                    frequency: "RegelmÃ¤ÃŸig",
                    experience: "AnfÃ¤nger",
                    notes: "Profil basierend auf GesprÃ¤chsanalyse erstellt"
                };
            }
            
            // âœ… VALIDIERUNG und BEREINIGUNG
            parsedData.name = parsedData.name || 'Neues Profil';
            parsedData.category = parsedData.category || parsedData.name;
            parsedData.goals = Array.isArray(parsedData.goals) ? parsedData.goals : [];
            parsedData.preferences = Array.isArray(parsedData.preferences) ? parsedData.preferences : [];
            parsedData.challenges = Array.isArray(parsedData.challenges) ? parsedData.challenges : [];
            
            console.log('ðŸ”¹ Final extracted profile data:', parsedData);
            return parsedData;
            
        } catch (error) {
            console.error('OpenAI Extract Profile Data Error:', error);
            throw new Error('Profildaten konnten nicht extrahiert werden');
        }
    }

    // âœ… HELPER METHODS fÃ¼r intelligente Extraktion
    cleanProfileName(input) {
        // Erste Buchstaben groÃŸ, Rest klein, Rechtschreibung bereinigen
        return input.trim()
            .split(' ')
            .map(word => word.charAt(0).toUpperCase() + word.slice(1).toLowerCase())
            .join(' ');
    }

    extractCategory(input) {
        const cleaned = this.cleanProfileName(input);
        // Nehme erstes Wort oder max 20 Zeichen
        return cleaned.split(' ')[0].substring(0, 20);
    }

    extractGoalsFromConversation(history) {
        const goals = [];
        const goalKeywords = ['ziel', 'erreichen', 'schaffen', 'mÃ¶chte', 'will', 'goal'];
        
        history.forEach(msg => {
            if (msg.role === 'user') {
                const lower = msg.content.toLowerCase();
                if (goalKeywords.some(keyword => lower.includes(keyword))) {
                    goals.push(msg.content.substring(0, 100));
                }
            }
        });
        
        return goals.slice(0, 3); // Max 3 goals
    }

    extractPreferencesFromConversation(history) {
        const preferences = [];
        const prefKeywords = ['mag', 'liebe', 'bevorzuge', 'gerne', 'am liebsten'];
        
        history.forEach(msg => {
            if (msg.role === 'user') {
                const lower = msg.content.toLowerCase();
                if (prefKeywords.some(keyword => lower.includes(keyword))) {
                    preferences.push(msg.content.substring(0, 100));
                }
            }
        });
        
        return preferences.slice(0, 3);
    }

    extractChallengesFromConversation(history) {
        const challenges = [];
        const challengeKeywords = ['schwierig', 'problem', 'herausforderung', 'schwer', 'struggle'];
        
        history.forEach(msg => {
            if (msg.role === 'user') {
                const lower = msg.content.toLowerCase();
                if (challengeKeywords.some(keyword => lower.includes(keyword))) {
                    challenges.push(msg.content.substring(0, 100));
                }
            }
        });
        
        return challenges.slice(0, 3);
    }

    async contextualChat(message, profileData = {}, conversationHistory = []) {
        if (!this.client) {
            throw new Error('OpenAI API nicht konfiguriert');
        }

        try {
            // âœ… VERBESSERTER KONTEXT basierend auf dynamischen Profilen
            let systemPrompt = `Du bist ALL-KI, ein personalisierter Assistent fÃ¼r den Nutzer.`;
            
            if (Object.keys(profileData).length > 0) {
                systemPrompt += `\n\nKontext Ã¼ber den Nutzer:
Profil: ${profileData.name || 'Unbekannt'} (Kategorie: ${profileData.category || 'Allgemein'})
Ziele: ${profileData.goals && profileData.goals.length > 0 ? profileData.goals.join(', ') : 'Keine spezifischen Ziele erwÃ¤hnt'}
Vorlieben: ${profileData.preferences && profileData.preferences.length > 0 ? profileData.preferences.join(', ') : 'Keine spezifischen Vorlieben erwÃ¤hnt'}
Herausforderungen: ${profileData.challenges && profileData.challenges.length > 0 ? profileData.challenges.join(', ') : 'Keine spezifischen Herausforderungen erwÃ¤hnt'}
Erfahrung: ${profileData.experience || 'Unbekannt'}
HÃ¤ufigkeit: ${profileData.frequency || 'Unbekannt'}
Zusatzinfos: ${profileData.notes || 'Keine zusÃ¤tzlichen Informationen'}

Nutze diese Informationen, um personalisierte, relevante und hilfreiche Antworten zu geben. 
Baue auf den Zielen und Vorlieben auf und hilf bei den Herausforderungen.`;
            }

            systemPrompt += `\n\nAntworte freundlich, hilfreich und auf Deutsch. 
Halte deine Antworten prÃ¤zise aber informativ. 
Stelle gelegentlich RÃ¼ckfragen um das Profil noch besser zu verstehen.`;

            // Build messages array
            const messages = [
                {
                    role: "system",
                    content: systemPrompt
                }
            ];

            // Add recent conversation history (last 10 messages to stay within limits)
            const recentHistory = conversationHistory.slice(-10);
            recentHistory.forEach(msg => {
                messages.push({
                    role: msg.role,
                    content: msg.content
                });
            });

            // Add current message
            messages.push({
                role: "user",
                content: message
            });

            const completion = await this.client.chat.completions.create({
                model: "gpt-3.5-turbo",
                messages: messages,
                max_tokens: 600,
                temperature: 0.7,
            });

            return completion.choices[0].message.content.trim();
        } catch (error) {
            console.error('OpenAI Contextual Chat Error:', error);
            throw new Error('Kontextuelle Antwort konnte nicht generiert werden');
        }
    }

    // Health check method
    async testConnection() {
        if (!this.client) {
            return { success: false, error: 'API Key nicht konfiguriert' };
        }

        try {
            const completion = await this.client.chat.completions.create({
                model: "gpt-4o-mini",
                messages: [
                    {
                        role: "user",
                        content: "Hallo! Antworte nur mit 'Test erfolgreich!'"
                    }
                ],
                max_tokens: 50,
                temperature: 0,
            });

            return { 
                success: true, 
                response: completion.choices[0].message.content.trim() 
            };
        } catch (error) {
            console.error('OpenAI Connection Test Error:', error);
            return { 
                success: false, 
                error: error.message 
            };
        }
    }
}

module.exports = new OpenAIService();